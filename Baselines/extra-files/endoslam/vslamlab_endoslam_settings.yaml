# VSLAM-LAB EndoSLAM Settings (Endo-SfMLearner)

# Dataset preprocessing
dataset:
  img_height: 256
  img_width: 320
  sequence_length: 3           # Number of source frames for pose estimation

# DispNet (Depth Estimation)
dispnet:
  encoder: "resnet18"
  num_scales: 4                # Multi-scale depth prediction
  min_depth: 0.1
  max_depth: 100.0

# PoseNet (Ego-motion Estimation)
posenet:
  encoder: "resnet18"
  num_input_frames: 2          # Number of input frames for pose
  rotation_mode: "euler"       # euler or quaternion

# Inference
inference:
  device: "cuda"
  use_gt_intrinsics: True      # Use ground truth camera intrinsics

# Loss weights (for reference, used during training)
loss:
  photometric_weight: 1.0
  smooth_weight: 0.1
  geometry_weight: 0.5

# Output
output:
  save_depth_maps: False
  depth_format: "png"          # png or npy
  trajectory_format: "tum"     # tum or kitti
